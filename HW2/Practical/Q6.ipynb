{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5l4mnZn03B"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi3BYfPQvnvd",
        "outputId": "396a2411-8dd7-48df-ca23-ec84b3060d9c"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "\n",
        "\n",
        "from torch.nn import Conv2d as Conv2D\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Upsample\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1EtK9dZH4pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7acaa2-6a48-4ede-a3b1-d42401979b81"
      },
      "source": [
        "!gdown --id 1opMhHAiMJVdD0eYAJEcuHZgTscgFBCpj\n",
        "!gdown --id 1uVs0yvi-HRj0yyez9MbnGwk_EsCHDLzl"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1opMhHAiMJVdD0eYAJEcuHZgTscgFBCpj\n",
            "To: /content/2d_images.zip.zip\n",
            "102MB [00:00, 143MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uVs0yvi-HRj0yyez9MbnGwk_EsCHDLzl\n",
            "To: /content/2d_masks.zip.zip\n",
            "100% 585k/585k [00:00<00:00, 80.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQwEuQi9U92t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5c7aee-b56b-4fc7-8276-fb7469185b3c"
      },
      "source": [
        "%mkdir Dataset\n",
        "%mkdir Dataset/2d_images\n",
        "%mkdir Dataset/2d_masks"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Dataset’: File exists\n",
            "mkdir: cannot create directory ‘Dataset/2d_images’: File exists\n",
            "mkdir: cannot create directory ‘Dataset/2d_masks’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhf6fHWlURN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3244d6-04af-4fb3-84c0-dcc239839575"
      },
      "source": [
        "\n",
        "!unzip -q 2d_images.zip.zip \n",
        "!unzip -q 2d_images.zip -d Dataset/2d_images\n",
        "\n",
        "!unzip -q 2d_masks.zip.zip \n",
        "!unzip -q 2d_masks.zip -d Dataset/2d_masks"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace Dataset/2d_images/ID_0000_Z_0142.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace Dataset/2d_images/ID_0001_Z_0146.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace Dataset/2d_images/ID_0002_Z_0162.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace Dataset/2d_images/ID_0003_Z_0132.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "replace Dataset/2d_masks/ID_0000_Z_0142.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDjVbTzKV9JI"
      },
      "source": [
        "!rm -rf 2d_images.zip.zip\n",
        "!rm -rf 2d_images.zip\n",
        "\n",
        "!rm -rf 2d_masks.zip.zip\n",
        "!rm -rf 2d_masks.zip"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr7lj5Hcyabk"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ukp9r5W9eZC"
      },
      "source": [
        "class CT_Data(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, root_dir):\n",
        "\n",
        "        self.image_frame = pd.read_csv(csv_file, skiprows=1)\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 0])\n",
        "        mask_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 1])\n",
        "        image = cv2.imread(img_name, 0)\n",
        "        image = cv2.resize(image,(32, 32))\n",
        "        image = image.reshape((1, 32, 32))\n",
        "        mask = cv2.imread(mask_name, 0)\n",
        "        mask = cv2.resize(mask, (32, 32))\n",
        "        mask = mask.reshape((1, 32, 32))\n",
        "        sample = {'image': image, 'mask': mask}\n",
        "        return sample"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4akgB1MbygYG"
      },
      "source": [
        "img_dir = \"Dataset/2d_images/\"\n",
        "msk_dir = \"Dataset/2d_masks/\"\n",
        "with open('Dataset/Dataset.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"filename\", \"mask\"])\n",
        "    for p in os.listdir(img_dir):\n",
        "        image_path = os.path.join(img_dir, p)\n",
        "        mask_path = os.path.join(msk_dir, p)\n",
        "        writer.writerow([image_path, mask_path])\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
        "data = data.iloc[np.random.permutation(len(data))]\n",
        "partition = int(len(data)*0.7)\n",
        "train, validation = data[:partition], data[partition:]\n",
        "train.to_csv(\"Dataset/Train.csv\", index=False)\n",
        "validation.to_csv(\"Dataset/Validation.csv\", index=False)\n",
        "\n",
        "train_dataset = CT_Data(csv_file='Dataset/Train.csv', root_dir='/content')\n",
        "val_dataset = CT_Data(csv_file='Dataset/Validation.csv', root_dir='/content')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=37, shuffle=True, num_workers=4)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=20, shuffle=True, num_workers=4)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPXR8tEIyhyw"
      },
      "source": [
        "## U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpsspcUc9AIY"
      },
      "source": [
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(Up, self).__init__()\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "        self.conv = nn.Sequential(\n",
        "            Conv2D(channel_in, channel_in, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_in),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Conv2D(channel_in, channel_out, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        x1 = self.upsample(x1)\n",
        "        diff_X = x1.size()[2] - x2.size()[2]\n",
        "        diff_Y = x1.size()[3] - x2.size()[3]\n",
        "        x2 = F.pad(x2, (diff_X // 2, int(diff_X / 2),diff_Y // 2, int(diff_Y / 2)))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x  \n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(Down, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            Conv2D(channel_in, channel_in, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_in),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Conv2D(channel_in, channel_out, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.max_pool2d(x,2)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, channel_in, classes):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.input_conv = nn.Sequential(\n",
        "            Conv2D(channel_in, channel_in, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_in),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Conv2D(channel_in, 64, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512,512)\n",
        "        self.up1 = Up(1024,256)\n",
        "        self.up2 = Up(512, 128)\n",
        "        self.up3 = Up(256, 64)\n",
        "        self.up4 = Up(128, 32)\n",
        "        self.output_conv = nn.Conv2d(32, classes, kernel_size = 1)  \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.input_conv(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5,x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        output = self.output_conv(x)\n",
        "        return F.sigmoid(output)\n",
        "    \n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.xavier_uniform(m.weight, gain=numpy.sqrt(2.0))\n",
        "        init.constant(m.bias, 0.1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IHuR2DYy7P9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgYtlFne9U3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5f1e97-f9a4-4282-bfd9-0260d76b0313"
      },
      "source": [
        "def iou_score(output, target):\n",
        "    smooth = 1e-5\n",
        "    oss = output > 0.5\n",
        "    tss = target > 0.5\n",
        "    intersection = (oss & tss).sum(axis=[1,2,3])\n",
        "    union = (oss | tss).sum(axis=[1,2,3])\n",
        "    return ((intersection + smooth) / (union + smooth)).mean()\n",
        "\n",
        "freq = 1\n",
        "model = UNet(1, 1)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "def train(model, epoch):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        data, target = Variable(data[\"image\"]), Variable(data[\"mask\"])\n",
        "        min_v = torch.min(target)\n",
        "        range_v = torch.max(target) - min_v\n",
        "        target = (target - min_v) / range_v\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data.float())\n",
        "\n",
        "        loss = criterion(output.float(), target.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % freq == 0:\n",
        "            print(f'Epoch-> {epoch} [{batch_idx * len(data)}/{len(train_dataloader.dataset)}'\n",
        "            f' ({100. * batch_idx / len(train_dataloader):.0f}%)],Loss Value-> { loss.data:.6f}')\n",
        "\n",
        "\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    total_iou = 0.0\n",
        "    for data in val_dataloader:\n",
        "        data, target = Variable(data[\"image\"], volatile=True), Variable(data[\"mask\"])\n",
        "        output = model(data.float())\n",
        "        min_v = torch.min(target)\n",
        "        range_v = torch.max(target) - min_v\n",
        "        target = (target - min_v) / range_v\n",
        "        test_loss += criterion(output.float(), target.float()).data\n",
        "        total_iou += iou_score(output, target)\n",
        "    test_loss /= len(val_dataloader.dataset)\n",
        "    total_iou /= len(val_dataloader)\n",
        "    print(f\"Loss Avg-> {test_loss} , IoU-> {total_iou}\")\n",
        "\n",
        "Num_of_eopchs = 15\n",
        "\n",
        "for epoch in range(1, Num_of_eopchs+1):\n",
        "    train(model, epoch)\n",
        "    test(model)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch-> 1 [0/185 (0%)],Loss Value-> 0.724115\n",
            "Epoch-> 1 [37/185 (20%)],Loss Value-> 0.614294\n",
            "Epoch-> 1 [74/185 (40%)],Loss Value-> 0.562589\n",
            "Epoch-> 1 [111/185 (60%)],Loss Value-> 0.525025\n",
            "Epoch-> 1 [148/185 (80%)],Loss Value-> 0.485882\n",
            "Loss Avg-> 0.03394114971160889 , IoU-> 4.566178901654894e-08\n",
            "Epoch-> 2 [0/185 (0%)],Loss Value-> 0.462656\n",
            "Epoch-> 2 [37/185 (20%)],Loss Value-> 0.445113\n",
            "Epoch-> 2 [74/185 (40%)],Loss Value-> 0.444252\n",
            "Epoch-> 2 [111/185 (60%)],Loss Value-> 0.420960\n",
            "Epoch-> 2 [148/185 (80%)],Loss Value-> 0.406321\n",
            "Loss Avg-> 0.03369342163205147 , IoU-> 0.0008982346625998616\n",
            "Epoch-> 3 [0/185 (0%)],Loss Value-> 0.408336\n",
            "Epoch-> 3 [37/185 (20%)],Loss Value-> 0.393662\n",
            "Epoch-> 3 [74/185 (40%)],Loss Value-> 0.390715\n",
            "Epoch-> 3 [111/185 (60%)],Loss Value-> 0.383085\n",
            "Epoch-> 3 [148/185 (80%)],Loss Value-> 0.376592\n",
            "Loss Avg-> 0.03179952874779701 , IoU-> 0.0001308536302531138\n",
            "Epoch-> 4 [0/185 (0%)],Loss Value-> 0.375189\n",
            "Epoch-> 4 [37/185 (20%)],Loss Value-> 0.379218\n",
            "Epoch-> 4 [74/185 (40%)],Loss Value-> 0.373278\n",
            "Epoch-> 4 [111/185 (60%)],Loss Value-> 0.361865\n",
            "Epoch-> 4 [148/185 (80%)],Loss Value-> 0.363243\n",
            "Loss Avg-> 0.02895733155310154 , IoU-> 0.05860302597284317\n",
            "Epoch-> 5 [0/185 (0%)],Loss Value-> 0.355514\n",
            "Epoch-> 5 [37/185 (20%)],Loss Value-> 0.371648\n",
            "Epoch-> 5 [74/185 (40%)],Loss Value-> 0.356969\n",
            "Epoch-> 5 [111/185 (60%)],Loss Value-> 0.353219\n",
            "Epoch-> 5 [148/185 (80%)],Loss Value-> 0.360039\n",
            "Loss Avg-> 0.024693619459867477 , IoU-> 0.5459836721420288\n",
            "Epoch-> 6 [0/185 (0%)],Loss Value-> 0.357048\n",
            "Epoch-> 6 [37/185 (20%)],Loss Value-> 0.356883\n",
            "Epoch-> 6 [74/185 (40%)],Loss Value-> 0.347807\n",
            "Epoch-> 6 [111/185 (60%)],Loss Value-> 0.349442\n",
            "Epoch-> 6 [148/185 (80%)],Loss Value-> 0.348595\n",
            "Loss Avg-> 0.02095092087984085 , IoU-> 0.7664097547531128\n",
            "Epoch-> 7 [0/185 (0%)],Loss Value-> 0.351874\n",
            "Epoch-> 7 [37/185 (20%)],Loss Value-> 0.346425\n",
            "Epoch-> 7 [74/185 (40%)],Loss Value-> 0.346523\n",
            "Epoch-> 7 [111/185 (60%)],Loss Value-> 0.342945\n",
            "Epoch-> 7 [148/185 (80%)],Loss Value-> 0.341726\n",
            "Loss Avg-> 0.018994297832250595 , IoU-> 0.8267568349838257\n",
            "Epoch-> 8 [0/185 (0%)],Loss Value-> 0.337588\n",
            "Epoch-> 8 [37/185 (20%)],Loss Value-> 0.345803\n",
            "Epoch-> 8 [74/185 (40%)],Loss Value-> 0.350423\n",
            "Epoch-> 8 [111/185 (60%)],Loss Value-> 0.339273\n",
            "Epoch-> 8 [148/185 (80%)],Loss Value-> 0.332090\n",
            "Loss Avg-> 0.018057530745863914 , IoU-> 0.8340879678726196\n",
            "Epoch-> 9 [0/185 (0%)],Loss Value-> 0.340424\n",
            "Epoch-> 9 [37/185 (20%)],Loss Value-> 0.346144\n",
            "Epoch-> 9 [74/185 (40%)],Loss Value-> 0.331628\n",
            "Epoch-> 9 [111/185 (60%)],Loss Value-> 0.330046\n",
            "Epoch-> 9 [148/185 (80%)],Loss Value-> 0.335095\n",
            "Loss Avg-> 0.01756039820611477 , IoU-> 0.8496371507644653\n",
            "Epoch-> 10 [0/185 (0%)],Loss Value-> 0.332319\n",
            "Epoch-> 10 [37/185 (20%)],Loss Value-> 0.332631\n",
            "Epoch-> 10 [74/185 (40%)],Loss Value-> 0.337674\n",
            "Epoch-> 10 [111/185 (60%)],Loss Value-> 0.330746\n",
            "Epoch-> 10 [148/185 (80%)],Loss Value-> 0.333511\n",
            "Loss Avg-> 0.017269983887672424 , IoU-> 0.8464013934135437\n",
            "Epoch-> 11 [0/185 (0%)],Loss Value-> 0.331219\n",
            "Epoch-> 11 [37/185 (20%)],Loss Value-> 0.327387\n",
            "Epoch-> 11 [74/185 (40%)],Loss Value-> 0.331599\n",
            "Epoch-> 11 [111/185 (60%)],Loss Value-> 0.333208\n",
            "Epoch-> 11 [148/185 (80%)],Loss Value-> 0.326848\n",
            "Loss Avg-> 0.016993284225463867 , IoU-> 0.8471713662147522\n",
            "Epoch-> 12 [0/185 (0%)],Loss Value-> 0.327669\n",
            "Epoch-> 12 [37/185 (20%)],Loss Value-> 0.332089\n",
            "Epoch-> 12 [74/185 (40%)],Loss Value-> 0.326478\n",
            "Epoch-> 12 [111/185 (60%)],Loss Value-> 0.320033\n",
            "Epoch-> 12 [148/185 (80%)],Loss Value-> 0.326179\n",
            "Loss Avg-> 0.017013173550367355 , IoU-> 0.8588567972183228\n",
            "Epoch-> 13 [0/185 (0%)],Loss Value-> 0.324278\n",
            "Epoch-> 13 [37/185 (20%)],Loss Value-> 0.319770\n",
            "Epoch-> 13 [74/185 (40%)],Loss Value-> 0.325920\n",
            "Epoch-> 13 [111/185 (60%)],Loss Value-> 0.322694\n",
            "Epoch-> 13 [148/185 (80%)],Loss Value-> 0.325631\n",
            "Loss Avg-> 0.016789164394140244 , IoU-> 0.8582916259765625\n",
            "Epoch-> 14 [0/185 (0%)],Loss Value-> 0.316842\n",
            "Epoch-> 14 [37/185 (20%)],Loss Value-> 0.323257\n",
            "Epoch-> 14 [74/185 (40%)],Loss Value-> 0.321504\n",
            "Epoch-> 14 [111/185 (60%)],Loss Value-> 0.315482\n",
            "Epoch-> 14 [148/185 (80%)],Loss Value-> 0.323819\n",
            "Loss Avg-> 0.01657138206064701 , IoU-> 0.8609223365783691\n",
            "Epoch-> 15 [0/185 (0%)],Loss Value-> 0.316894\n",
            "Epoch-> 15 [37/185 (20%)],Loss Value-> 0.318975\n",
            "Epoch-> 15 [74/185 (40%)],Loss Value-> 0.315039\n",
            "Epoch-> 15 [111/185 (60%)],Loss Value-> 0.319398\n",
            "Epoch-> 15 [148/185 (80%)],Loss Value-> 0.314119\n",
            "Loss Avg-> 0.016466999426484108 , IoU-> 0.8653186559677124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlWhUQcMyW8x"
      },
      "source": [
        "## Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPMTvh_3zByn"
      },
      "source": [
        "visualize output of your trained network on 5 data from validation dataset, and compare it with ground truth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-OqCrJbggW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "83afe5a0-4c66-43b3-a250-666f0af61f86"
      },
      "source": [
        "iteration = iter(val_dataloader)\n",
        "batch = iteration.next()\n",
        "images, labels = batch['image'], batch['mask']\n",
        "with torch.no_grad():\n",
        "  outputs = model(images.float())\n",
        "\n",
        "def show(img, ax):\n",
        "    npimg = img.numpy()\n",
        "    ax.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "out_samples = outputs[:5]\n",
        "label_samples = labels[:5]\n",
        "pred_grid = utils.make_grid(255*(out_samples >= 0.5) , nrow=5)\n",
        "gt_grid = utils.make_grid(label_samples , nrow=5)\n",
        "f, (ax0,ax1) = plt.subplots(1,2,figsize=(15,15))\n",
        "ax0.set_title('Ground Truth is:')\n",
        "ax1.set_title('Our Prediction is:')\n",
        "show(gt_grid, ax0)\n",
        "show(pred_grid, ax1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLThQ1kxzT0o"
      },
      "source": [
        "## Improve U-Net (bonus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3RHpUhyzm1Z"
      },
      "source": [
        "improve U-Net and compare accuracy and networks outputs with previous parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tj1WoVzUms"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}